#!/bin/bash
#SBATCH --job-name=SimID_35189106_0_
#SBATCH --nodes=1
#SBATCH --output=/home/FCAM/vasilescu/vcell-batch-job/logs/submit_vcell_batch.log
##SBATCH -o %x.stdout       # alternately, uncomment and use these 2 instead of --output above
##SBATCH -e %x.stderr
#SBATCH --ntasks=4              # how many tasks to run in parallel
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=8G        # ntasks x cpus-per-task = 4 x 1  --> 4 x 8G = 32G
#SBATCH --time=01:00:00         # 1 hour timeout
#SBATCH --partition=vcell
#SBATCH --qos=vcell

# slurm built-in placeholders
# %j    job ID
# %x    job name
# %u    user name

# shell variables
BASE_DIR=/home/FCAM/vasilescu/vcell-batch-job
CONTAINER_IMAGE=$BASE_DIR/container/vcell-batch_7.7.0.30.sif
INPUT_DIR=$BASE_DIR/input
OUTPUT_DIR=$BASE_DIR/output
LOG_DIR=$BASE_DIR/logs
SIMXML="${INPUT_DIR}/${SLURM_JOB_NAME}_0.simtask.xml"

log_file="${LOG_DIR}/${SLURM_JOB_NAME}_sub.log"         # slurm script log
total_jobs=10           # total number of jobs to run
timeout_duration=300s   # maximum allowed runtime for each job (5m may work too)
max_concurrent_jobs=$SLURM_NTASKS  # number of jobs allowed at once

# Clear the log file at the start
echo "Job Execution Log" > "${log_file}"
echo "------------------" >> "${log_file}"
echo "=== [$(date)] === SLURM job started on node $(hostname)"
echo "=== [$(date)] === SLURM job started on node $(hostname)" >> "${log_file}"
sleep 2

echo "[Preprocess] Running JavaPreprocessor64..."
echo "[Preprocess] Running JavaPreprocessor64..." >> "${log_file}"
singularity exec --cleanenv \
  --bind $INPUT_DIR:$INPUT_DIR \
  --bind $OUTPUT_DIR:$OUTPUT_DIR \
  $CONTAINER_IMAGE \
  JavaPreprocessor64 $SIMXML $OUTPUT_DIR

# ------------------------------------------------------------------

declare -A job_pid_map  # associative array to store job index -> PID mapping
job_pids=()  # list to track PIDs
running_jobs=0

for i in $(seq 0 $((total_jobs - 1))); do
    # log job start
    echo "Job $i started at $(date)" >> "${log_file}"
    # run each script in parallel
    timeout $timeout_duration srun -N 1 -n 1 -c 1 \
       singularity exec --cleanenv \
      --bind $INPUT_DIR:$INPUT_DIR \
      --bind $OUTPUT_DIR:$OUTPUT_DIR \
      $CONTAINER_IMAGE \
      langevin_x64 simulate \
        "${INPUT_DIR}/${SLURM_JOB_NAME}.langevinInput" \
        $i \
        --output-log="${LOG_DIR}/${SLURM_JOB_NAME}_${i}.log" \
        --vc-print-status &
    pid=$!  # capture the job PID
    job_pids+=($pid)  # store the PID
    job_pid_map[$pid]=$i  # map job index to PID
    ((running_jobs++))  # increment running job count

    # wait for a finished job before launching a new one if we hit the concurrency limit
    while (( running_jobs >= max_concurrent_jobs )); do
        for idx in "${!job_pids[@]}"; do
            pid="${job_pids[$idx]}"
            if ! kill -0 "$pid" 2>/dev/null; then  # check if process is still running
                wait "$pid"  # ensure exit status is collected
                exit_code=$?
                job_index=${job_pid_map[$pid]}  # retrieve original job index
                echo "Job $job_index with PID $pid finished with exit code $exit_code at $(date)" >> "${log_file}"
                unset "job_pids[$idx]"  # remove PID from list
                unset "job_pid_map[$pid]"  # remove mapping
                ((running_jobs--))  # decrement count
                break  # break once we free up a slot
            fi
        done
        sleep 1  # allow brief pause before rechecking
    done
done

# final wait for any remaining jobs
for pid in "${job_pids[@]}"; do
    wait $pid
    exit_code=$?
    job_index=${job_pid_map[$pid]}  # retrieve original job index
    echo "Job $job_index with PID $pid finished with exit code $exit_code at $(date)" >> "${log_file}"
done
echo "Batch jobs completed at $(date)" >> "${log_file}"

echo "Starting the last job at $(date)" >> "${log_file}"
timeout $timeout_duration srun -N 1 -n 1 -c 1 \
       singularity exec --cleanenv \
      --bind $INPUT_DIR:$INPUT_DIR \
      --bind $OUTPUT_DIR:$OUTPUT_DIR \
      $CONTAINER_IMAGE \
      langevin_x64 postprocess \
        "${INPUT_DIR}/${SLURM_JOB_NAME}.langevinInput" \
        $total_jobs \
        --output-log="${LOG_DIR}/${SLURM_JOB_NAME}_P.log" \
        --vc-print-status &
last_pid=$!
wait $last_pid  # explicitly wait for last.sh to finish
exit_code=$?    # capture the exit code of the job
echo "Job 'Last' with PID $last_pid finished with exit code $exit_code at $(date)" >> "${log_file}"
echo "The final job finished at $(date)" >> "${log_file}"

echo "All jobs completed at $(date)" >> "${log_file}"


echo "[Postprocess] Running JavaPostprocessor64..."
echo "[Postprocess] Running JavaPostprocessor64..." >> "${log_file}"
singularity exec --cleanenv \
  --bind $OUTPUT_DIR:$OUTPUT_DIR \
  $CONTAINER_IMAGE \
  JavaPostprocessor64 35189106 vasilescu 17 0 0 10 $SLURM_JOB_SCRIPT

echo "=== [$(date)] === SLURM job completed"
echo "=== [$(date)] === SLURM job completed" >> "${log_file}"
